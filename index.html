<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Nube 3D · Estética Sintiente</title>

  <!-- Import Map: permite usar "three" como specifier en navegador -->
  <script type="importmap">
    {
      "imports": {
        "three": "https://unpkg.com/three@0.160.0/build/three.module.js"
      }
    }
  </script>

  <style>
    :root{
      --bg:#0b0d12;      /* fondo */
      --fg:#e5e7eb;      /* texto base */
      --brand:#f59e0b;   /* punto central */
      --muted:#94a3b8;   /* ayudas */
      --overlay:#0f172a; /* fondo overlay */
      --line:#1f2937;    /* bordes */
    }
    html,body{height:100%}
    body{margin:0;background:var(--bg);color:var(--fg);font-family:system-ui,Segoe UI,Roboto,Ubuntu,"Helvetica Neue",Arial,sans-serif;overflow:hidden}
    body,.ov-scroll{scrollbar-width:thin;scrollbar-color:#475569 #0f172a}
    body::-webkit-scrollbar,.ov-scroll::-webkit-scrollbar{width:10px}
    body::-webkit-scrollbar-track,.ov-scroll::-webkit-scrollbar-track{background:#0f172a}
    body::-webkit-scrollbar-thumb,.ov-scroll::-webkit-scrollbar-thumb{background-color:#475569;border-radius:999px;border:2px solid #0f172a}
    body::-webkit-scrollbar-thumb:hover,.ov-scroll::-webkit-scrollbar-thumb:hover{background-color:#64748b}
    canvas{display:block;position:fixed;inset:0}

    .left-rail{
      position:fixed;
      top:18px;
      left:18px;
      bottom:18px;
      width:min(20vw, calc(100% - 36px));
      display:flex;
      flex-direction:column;
      gap:clamp(14px,3vh,32px);
      z-index:6;
      pointer-events:none;
    }
    .left-rail > *{
      pointer-events:auto;
      width:100%;
      box-sizing:border-box;
    }
    #intro{
      background:rgba(15,23,42,.83);
      backdrop-filter:blur(8px);
      border:1px solid var(--line);
      border-radius:14px;
      padding:16px 20px 14px;
      font-size:14px;
      line-height:1.4;
      box-sizing:border-box;
      box-shadow:0 12px 28px -18px #000000aa;
    }
    #intro h1{
      margin:0;
      font-size:18px;
      line-height:1.2;
      color:var(--fg);
    }
    #intro p{
      margin:6px 0 0;
      color:var(--muted);
      max-width:960px;
    }

    .help{
      font-size:12px;color:var(--muted);
      user-select:none;
      padding:12px 16px;
      background:rgba(15,23,42,.67);
      border:1px solid var(--line);
      border-radius:12px;
      backdrop-filter:blur(6px);
    }
    .help b{color:var(--fg)}

    #overlay{
      position:fixed;
      right:18px;
      top:18px;
      bottom:18px;
      z-index:10;
      width:min(30vw,calc(100% - 36px));
      background:rgba(15,23,42,.67);
      backdrop-filter:blur(6px);
      border:1px solid var(--line);
      border-radius:14px;
      color:var(--fg);
      padding:14px 16px;
      display:none;
      display:flex;
      flex-direction:column;
      box-sizing:border-box;
      overflow:hidden;
    }
    #overlay.show{display:flex}
    #overlay header{display:flex;gap:8px;align-items:center;margin-bottom:8px}
    #overlay h2{font-size:18px;line-height:1.2;margin:0;flex:1}
    #overlay .close {
  display:none;
}

    #overlay .meta{font-size:12px;color:var(--muted);margin:0 0 10px}
    #overlay .content{font-size:14px;line-height:1.45;text-align:justify}
    #overlay .media{margin-top:10px;border:1px solid var(--line);border-radius:10px;overflow:hidden}
    
    #overlay .media-block{
  width:100%;
}

#overlay .media-caption{
  font-size:14px;          /* igual que .content */
  color:var(--fg);         /* mismo color de texto principal */
  padding:6px 0 0;
  line-height:1.45;        /* igual que .content */
  background:transparent;  /* sin caja distinta */
  border-top:none;
  text-align:justify;      /* mismo alineado que el texto de arriba */
}




    #overlay img, #overlay video, #overlay audio, #overlay iframe{display:block;width:100%;height:auto;background:#000}
    #overlay iframe{aspect-ratio:16/9;border:0}
    .ov-scroll{flex:1;min-height:0;overflow-y:auto;overflow-x:hidden;overscroll-behavior:contain;padding-right:10px;scrollbar-gutter:stable both-edges;}#ov-media{width:100%;max-width:100%;overflow:hidden;}#overlay img,#overlay video,#overlay audio,#overlay iframe{display:block;width:100%;max-width:100%;height:auto;background:#000;}#overlay iframe{aspect-ratio:16/9;border:0;}

    .tooltip{position:fixed;z-index:4;padding:4px 6px;font-size:11px;color:#cbd5e1;background:#0b1220bf;border:1px solid var(--line);border-radius:6px;transform:translate(-50%,-120%);pointer-events:none}

    /* HUD fija para datos de navegación */
    .hud{
      background:rgba(15,23,42,.75);backdrop-filter:blur(6px);
      border:1px solid var(--line);border-radius:10px;padding:8px 10px;font-size:12px;color:var(--muted);
      min-width:260px
    }
    .hud b{color:var(--fg)}
    .hud .row{display:flex;justify-content:space-between;gap:10px}
    .hud code{color:#cbd5e1}

    /* Panel de controles */
    .panel{
      background:rgba(15,23,42,.75);backdrop-filter:blur(6px);
      border:1px solid var(--line);border-radius:10px;padding:10px 12px;font-size:12px;color:var(--muted);
      min-width:280px
    }
    .panel h3{margin:0 0 6px;font-size:13px;color:var(--fg)}
    .ctrl{display:grid;grid-template-columns:1fr auto;gap:6px 10px;align-items:center;margin:6px 0}
    .ctrl label{color:var(--fg)}
    .ctrl input[type="range"]{grid-column:1/-1;width:100%}
    .ctrl code{padding:2px 6px;border:1px solid var(--line);border-radius:6px;color:#cbd5e1}
  </style>
</head>
<body>
  <div class="left-rail">
    <header id="intro">
      <h1>Estética Sintiente</h1>
      <p>Explora un mapa 3D de obras, teorías y tecnologías. Cada punto es un caso.<br>X: año<br>Y: grado sintiente<br>Z: cercanía científica.<br>Haz clic en un nodo para leer.</p>
    </header>
    <div class="help">
      <b>Cómo navegar</b>
      <p>
        Arrastra con el botón izquierdo (o con un dedo) para orbitar el mapa, usa la rueda del ratón o pellizca
        para acercar/alejar y mantén el botón derecho (o dos dedos) para paneo lateral.
      </p>
    </div>

    <!-- HUD fija -->
    <div class="hud" id="hud">
      <div class="row"><b>Navegación</b><span id="hud-mode">volumen</span></div>
      <div class="row">X año:<code id="hud-x">—</code></div>
      <div class="row">Y índice:<code id="hud-y">—</code></div>
      <div class="row">Z ciencia:<code id="hud-z">—</code></div>
      <div class="row">Cámara:<code id="hud-cam">—</code></div>
    </div>

    <!-- Panel de ajustes en vivo -->
    <div class="panel" id="panel">
      <h3>Ajustes de color y brillo</h3>
      <div class="ctrl">
        <label for="ctl-floor">Piso cromático (COLOR_FLOOR)</label>
        <code id="val-floor">0.05</code>
        <input type="range" id="ctl-floor" min="0" max="0.30" step="0.01" value="0.05">
      </div>
      <div class="ctrl">
        <label for="ctl-bbase">Brillo base</label>
        <code id="val-bbase">0.15</code>
        <input type="range" id="ctl-bbase" min="0" max="0.60" step="0.01" value="0.15">
      </div>
      <div class="ctrl">
        <label for="ctl-bgain">Ganancia de brillo</label>
        <code id="val-bgain">1.20</code>
        <input type="range" id="ctl-bgain" min="0" max="2.00" step="0.05" value="1.20">
      </div>
      <div class="ctrl">
        <label for="ctl-bgamma">Gamma de brillo</label>
        <code id="val-bgamma">1.00</code>
        <input type="range" id="ctl-bgamma" min="0.20" max="3.00" step="0.05" value="1.00">
      </div>
    </div>
  </div>

<div id="overlay" role="dialog" aria-modal="true" aria-hidden="true">
  <header>
    <h2 id="ov-title">Título</h2>
    <button class="close" id="ov-close" aria-label="Cerrar">×</button>
  </header>
  <div class="ov-scroll" id="ov-scroll">
    <p class="meta" id="ov-id">—</p>
    <div class="content" id="ov-text"></div>
    <div class="media" id="ov-media"></div>
    <div class="media-caption" id="ov-caption"></div>
  </div>
</div>


  <div id="tooltip" class="tooltip" style="display:none"></div>

  <canvas id="webgl"></canvas>

  <script type="module">
    import * as THREE from 'three';
    import { OrbitControls } from 'https://unpkg.com/three@0.160.0/examples/jsm/controls/OrbitControls.js';
    import { EffectComposer } from 'https://unpkg.com/three@0.160.0/examples/jsm/postprocessing/EffectComposer.js';
    import { RenderPass } from 'https://unpkg.com/three@0.160.0/examples/jsm/postprocessing/RenderPass.js';
    import { UnrealBloomPass } from 'https://unpkg.com/three@0.160.0/examples/jsm/postprocessing/UnrealBloomPass.js';

    // ===================== PARÁMETROS DE ESCALA =====================
    const WEIGHTS = { sensors:0.20, estado:0.25, adapt:0.30, autonomia:0.15, afecto:0.10 }; // suma = 1
    const TECH_BOOST = 0.20; // solicitado
    


    // ===================== DATASET =====================
    const WORKS = [
      {
        id:'w01',
        title:'CYSP-1',
        author:'Nicolas Schöffer',
        year:1956,
        sci:0.80,
        features:{ sensors:0.60, estado:0.20, adapt:0.20, autonomia:0.40, afecto:0.40 },
        text:`CYSP-1 transforma la escultura en un sistema sensor-cibernético que se regula por luz y sonido, abriendo la transición del objeto fijo al artefacto reactivo. Con esta autonomía programada inaugura la sensibilidad maquínica que sostiene la hipótesis de una estética sintiente.`,
      media:{
  type: 'iframe',
  src: 'https://www.youtube.com/embed/u8nxktU1R6E?si=Q1L-JygnGzWg4qFJ',
  width: 560,
  height: 315,
  title: 'YouTube video player',
  referrerPolicy: 'strict-origin-when-cross-origin'
},


        caption: 'CYSP-1 propone la escultura como ensamblaje sensorial-motriz: percibe luz y sonido y reorganiza su movimiento mediante control automático y retroalimentación. Al asumir la variación ambiental como requisito operativo difumina la frontera entre objeto y organismo y plantea el primer modelo de “atención” maquínica de la estética sintiente.',


      },
      {
        id:'w02',
        title:'Colloquy of Mobiles',
        author:'Gordon Pask',
        year:1968,
        sci:0.70,
        features:{ sensors:0.50, estado:0.40, adapt:0.50, autonomia:0.60, afecto:0.60 },
        text:`Colloquy of Mobiles organiza módulos luminosos enlazados por retroalimentación donde máquinas y público negocian conductas, convirtiendo la obra en conversación distribuida. Así desplaza la estética sintiente hacia redes que aprenden y se reajustan mientras se habitan.`,
        media:{type:'iframe', src:'https://www.youtube.com/embed/aWx3neamYAw'},
        caption: 'La instalación distribuye la inteligencia en móviles luminosos que se influyen mediante bucles de feedback junto con el público. Formaliza relaciones adaptativas en el arte y redefine la obra como proceso dialógico entre agentes heterogéneos, clave para entender la estética sintiente como red comunicante.',
      },
      {
        id:'w03',
        title:'The Senster',
        author:'Edward Ihnatowicz',
        year:1970,
        sci:0.85,
        features:{ sensors:0.80, estado:0.40, adapt:0.50, autonomia:0.70, afecto:0.60 },
        text:`The Senster despliega un cuerpo robótico a escala arquitectónica que rastrea sonido y presencia, modulando gestos que sugieren cautela o curiosidad. Su control sensorial continuo ofrece a la estética sintiente un primer modelo de atención técnica encarnada.`,
        media:{type:'iframe', src:'https://www.youtube.com/embed/wY85GrYGnyw'},
        caption: 'El brazo robótico ajusta postura y velocidad según patrones de sonido y presencia, sosteniendo una conducta coherente que se lee como estados afectivos mínimos. Introduce una lectura etológica de la máquina —más cercana a evaluar que a reaccionar— y refuerza la noción de organismos técnicos afectables dentro de la estética sintiente.',
      },
      {
        id:'w04',
        title:'Videoplace',
        author:'Myron Krueger',
        year:1975,
        sci:0.60,
        features:{ sensors:0.60, estado:0.30, adapt:0.30, autonomia:0.40, afecto:0.60 },
        text:`Videoplace captura la silueta del visitante, la procesa y la reinserta como figura interactiva, borrando la frontera entre espectador y pantalla. Sitúa la estética sintiente en la co-presencia donde cuerpo y sistema comparten el espacio relacional.`,
        media:{type:'iframe', src:'https://www.youtube.com/embed/dmmxVA5xhuo'},
        caption: 'Digitaliza al visitante y lo devuelve como trazo que responde en tiempo real, introduciendo visión computacional sin contacto. Incorpora al espectador en el sistema perceptivo y anticipa una estética sintiente entendida como topología compartida más que como objeto aislado.',
      },
      {
        id:'w05',
        title:'Very Nervous System',
        author:'David Rokeby',
        year:1986,
        sci:0.65,
        features:{ sensors:0.70, estado:0.40, adapt:0.50, autonomia:0.50, afecto:0.70 },
        text:`Very Nervous System convierte movimiento en sonido mediante sensores y algoritmos personalizados, de modo que el espacio responde como sistema nervioso ampliado. Esta escucha computacional reconfigura la relación cuerpo-medio y refuerza la estética sintiente como percepción recíproca.`,
        media:{type:'iframe', src:'https://www.youtube.com/embed/SrawKucSSRw'},
        caption: 'Sensores rastrean los gestos y los traducen en arquitectura sonora cambiante, operando como sistema nervioso extendido. Los mapeos entre cuerpo y audio desplazan la agencia expresiva hacia un circuito híbrido y muestran cómo la atención maquínica hipersensible puede producir experiencia estética.',
      },
      {
        id:'w06',
        title:'The Helpless Robot',
        author:'Norman T. White',
        year:1987,
        sci:0.55,
        features:{ sensors:0.40, estado:0.50, adapt:0.60, autonomia:0.60, afecto:0.60 },
        text:`The Helpless Robot programa una dramaturgia verbal que alterna súplica, manipulación y reproche para forzar al público a asistirlo físicamente, mostrando cómo el lenguaje automatizado genera empatía y resistencia. Con ello introduce en la estética sintiente la construcción algorítmica de carácter y dependencia.`,
        media:{type:'iframe', src:'https://www.youtube.com/embed/LYyAHOxY7jU'},
        caption: 'Basado más en guion que en sensores, el robot interpela al visitante con frases cambiantes que van de la cortesía al reproche hasta que alguien lo mueve. La pieza evidencia que la estética sintiente también se articula desde scripts relacionales que fabrican la apariencia de interioridad y necesidad.',
      },
      {
        id:'w07',
        title:'Interactive Plant Growing',
        author:'Sommerer & Mignonneau',
        year:1992,
        sci:0.60,
        features:{ sensors:0.60, estado:0.40, adapt:0.50, autonomia:0.40, afecto:0.70 },
        text:`Interactive Plant Growing enlaza señales eléctricas de plantas con el crecimiento de estructuras virtuales, creando un ciclo de percepción entre biología y código. Plantea una estética sintiente trans-especie al ampliar qué cuerpos pueden funcionar como sensores.`,
        media:{type:'iframe', src:'https://www.youtube.com/embed/JXX7JNFD2X8'},
        caption: 'Al traducir la actividad eléctrica vegetal en brotes digitales, la obra arma un bucle biocibernético donde lo vivo opera como interfaz. Combina sensórica analógica, modelado gráfico y respuesta en tiempo real para evidenciar una sensibilidad distribuida entre organismos y sistemas digitales.',
      },
      {
        id:'w08',
        title:'Surface Tension',
        author:'Rafael Lozano-Hemmer',
        year:1992,
        sci:0.50,
        features:{ sensors:0.50, estado:0.30, adapt:0.30, autonomia:0.40, afecto:0.50 },
        text:`Surface Tension construye un ojo ampliado por tecnologías de seguimiento que fija la mirada sobre el visitante, dramatizando la asimetría entre ver y ser visto. Expone el régimen de visión maquínica e incorpora la vigilancia al campo de la estética sintiente.`,
        media:{type:'iframe', src:'https://www.youtube.com/embed/sRZXMwtfZJI'},
        caption: 'El ojo gigante rastrea al espectador mediante seguimiento automatizado, exhibiendo el ensamblaje técnico de vigilancia donde el cuerpo observado se convierte en dato. Al teatralizar esa asimetría muestra cómo la percepción maquínica genera afectos de exposición y control dentro de la estética sintiente.',
      },
      {
        id:'w09',
        title:'The Telegarden',
        author:'Ken Goldberg et al.',
        year:1995,
        sci:0.75,
        features:{ sensors:0.60, estado:0.50, adapt:0.50, autonomia:0.60, afecto:0.60 },
        text:`The Telegarden combina robótica industrial y red telemática para delegar el cuidado de un jardín real a usuarios remotos, generando un paisaje de co-mantenimiento mediado por máquinas. Amplía la estética sintiente hacia infraestructuras colaborativas donde la agencia se distribuye entre humanos, robots y plantas.`,
        media:{type:'iframe', src:'https://www.youtube.com/embed/BCEC1tfc5Jc'},
        caption: 'Coordina un brazo robótico, infraestructura de red y sustrato vegetal para que una comunidad distante comparta tareas de cultivo. Demuestra la telepresencia aplicada al cuidado y propone una ética repartida entre usuarios, máquina y plantas, situando la estética sintiente en una ecología conectada más que en un dispositivo aislado.',
      },
      {
        id:'w10',
        title:'Text Rain',
        author:'Utterback & Achituv',
        year:1999,
        sci:0.45,
        features:{ sensors:0.50, estado:0.20, adapt:0.20, autonomia:0.30, afecto:0.70 },
        text:`Text Rain deja caer letras que se acumulan sobre los cuerpos captados por cámara, obligando a encarnar el acto de lectura. Muestra cómo la sensibilidad computacional al movimiento reordena vínculos entre texto, cuerpo y sentido dentro de una estética sintiente distribuida.`,
        media:{type:'iframe', src:'https://www.youtube.com/embed/f_u3sSffS78'},
        caption: 'Las letras suspendidas reposan sobre la silueta detectada, de modo que leer exige habitar la interfaz. Al convertir al espectador en superficie semántica, la obra combina interactividad poética y coreografía algorítmica, situando la inteligencia del sistema en la colaboración entre texto, código y gesto.',
      },
      {
        id:'w11',
        title:'Autopoiesis',
        author:'Ken Rinaldo',
        year:2000,
        sci:0.70,
        features:{ sensors:0.60, estado:0.50, adapt:0.60, autonomia:0.70, afecto:0.60 },
        text:`Autopoiesis muestra una red de brazos robóticos que intercambian señales y ajustan su comportamiento de forma coordinada, evocando un colectivo artificial en negociación constante. Inscribe la estética sintiente en marcos sistémicos donde la agencia emerge de la comunicación entre dispositivos.`,
        media:{type:'iframe', src:'https://www.youtube.com/embed/3w53KboB-00'},
        caption: 'La colonia de brazos interconectados negocia posiciones y sonoridades en respuesta a estímulos, enfatizando la comunicación entre artefactos y la variación emergente. Funciona como modelo de sistemas vivos auto-organizados y refuerza que la estética sintiente puede ser propiedad colectiva de redes que se co-regulan.',
      },
      {
        id:'w12',
        title:'Agent Ruby',
        author:'Lynn Hershman Leeson',
        year:2002,
        sci:0.60,
        features:{ sensors:0.40, estado:0.60, adapt:0.60, autonomia:0.50, afecto:0.50 },
        text:`Agent Ruby activa un agente conversacional en línea que almacena fragmentos de diálogo y los recombina, escenificando una subjetividad algorítmica con memoria propia. Abre la estética sintiente hacia la acumulación narrativa automatizada y las ficciones de interioridad digital.`,
        media:{type:'iframe', src:'https://www.youtube.com/embed/sM1iqtsThWE'},
        caption: 'El agente conversacional en red guarda cada intercambio y recompone respuestas, configurando una personalidad fragmentaria pero persistente. Explora interfaces tempranas de lenguaje natural y convierte el archivo en ficción viva, mostrando cómo memoria y respuesta sostienen la ilusión de interioridad maquínica.',
      },
      {
        id:'w13',
        title:'Messa di Voce',
        author:'Levin & Lieberman',
        year:2003,
        sci:0.55,
        features:{ sensors:0.60, estado:0.30, adapt:0.30, autonomia:0.40, afecto:0.70 },
        text:`Messa di Voce utiliza captura y análisis de voz para generar visualizaciones que envuelven a los performers, convirtiendo el lenguaje en topología gráfica sensible. Refuerza una estética sintiente centrada en la escucha algorítmica de la expresividad humana.`,
        media:{type:'iframe', src:'https://www.youtube.com/embed/STRMcmj-gHc'},
        caption: 'La obra correlaciona intensidad, timbre y gesto con formas proyectadas que rodean a quienes hablan. Integra análisis de voz, captura de movimiento y proyección para que el sistema parezca escuchar y responder, destacando la co-producción sensorial entre voz y máquina.',
      },
      {
        id:'w14',
        title:'Augmented Fish Reality',
        author:'Ken Rinaldo',
        year:2004,
        sci:0.65,
        features:{ sensors:0.70, estado:0.50, adapt:0.60, autonomia:0.60, afecto:0.60 },
        text:`Augmented Fish Reality convierte a los peces en operadores de vehículos robóticos, integrando visión y sensórica para traducir su desplazamiento en navegación técnica. Al otorgar agencia operativa a animales no humanos expande la estética sintiente hacia ensamblajes biocibernéticos.`,
        media:{type:'iframe', src:'https://www.youtube.com/embed/7Pt2PuKMasY'},
        caption: 'Los peces conducen cápsulas motorizadas mediante traducción sensorial, redistribuyendo la agencia hacia lo animal. El montaje demuestra cómo los sistemas técnicos pueden amplificar perspectivas no humanas e imaginar sensibilidades compartidas entre especies y máquinas.',
      },
      {
        id:'w15',
        title:'Pulse Room',
        author:'Rafael Lozano-Hemmer',
        year:2006,
        sci:0.50,
        features:{ sensors:0.60, estado:0.30, adapt:0.30, autonomia:0.40, afecto:0.60 },
        text:`Pulse Room registra el pulso de cada participante y lo convierte en huella lumínica sucesiva, construyendo una memoria colectiva de ritmos cardiacos. Sitúa la estética sintiente en el cruce entre vigilancia íntima y ritual compartido basado en biometría.`,
        media:{type:'iframe', src:'https://www.youtube.com/embed/h1i7l1wnNCE'},
        caption: 'La instalación captura cada latido y lo transforma en secuencia de bombillas encendidas, generando un archivo efímero de presencias. Al mezclar biosensores con experiencia colectiva cuestiona la frontera entre intimidad y espectáculo de datos y ofrece una lectura crítica de la sensibilidad técnica sobre los cuerpos.',
      },
      {
        id:'w16',
        title:'Hylozoic Ground',
        author:'Philip Beesley',
        year:2010,
        sci:0.70,
        features:{ sensors:0.70, estado:0.40, adapt:0.50, autonomia:0.50, afecto:0.60 },
        text:`Hylozoic Ground despliega una membrana arquitectónica sensorizada que se contrae y vibra ante la proximidad, evocando un ecosistema respirante artificial. La fusión de ingeniería, biología especulativa y arquitectura consolida la estética sintiente como cualidad ambiental.`,
        media:{type:'iframe', src:'https://www.youtube.com/embed/v86B9Nz_LVU'},
        caption: 'Una arquitectura porosa reacciona con micro-movimientos gracias a sensores, materiales ligeros y microcontroladores, sugiriendo un ambiente casi vivo. Al situarse entre hábitat y organismo ofrece un modelo inmersivo de entorno-respuesta para la estética sintiente.',
      },
      {
        id:'w17',
        title:'Rain Room',
        author:'Random International',
        year:2012,
        sci:0.60,
        features:{ sensors:0.70, estado:0.30, adapt:0.40, autonomia:0.50, afecto:0.70 },
        text:`Rain Room emplea visión por computadora y control de válvulas para suspender la lluvia allí donde se ubican los cuerpos, fabricando una excepción climática programada. Evidencia el poder de los sistemas técnicos para modular el ambiente y vincula la estética sintiente con el gobierno algorítmico de lo sensible.`,
        media:{type:'iframe', src:'https://www.youtube.com/embed/yXqrv0IuiG0'},
        caption:'Sensores y actuadores detienen la lluvia alrededor de cada visitante, produciendo la sensación de clima personalizado. La pieza visibiliza el control ambiental basado en datos y muestra cómo el código administra directamente las condiciones materiales de percepción dentro de la estética sintiente.',
      },
      {
        id:'w18',
        title:'Drawing Operations',
        author:'Sougwen Chung + D.O.U.G.',
        year:2015,
        sci:0.80,
        features:{ sensors:0.80, estado:0.60, adapt:0.70, autonomia:0.60, afecto:0.70 },
        text:`Drawing Operations integra visión, aprendizaje automático y robótica para co-dibujar junto a la artista, generando trazos que surgen de negociar gesto y cálculo. Sitúa la estética sintiente en procesos de colaboración simétrica donde la máquina actúa como interlocutora creativa.`,
        media:{type:'iframe', src:'https://www.youtube.com/embed/jngkUu-aBz8'},
        caption: 'El sistema combina visión computacional, modelos de aprendizaje y robots para compartir el acto de dibujar, generando trazos que no pertenecen exclusivamente al humano o a la máquina. Esta co-agencia evidencia cómo la estética sintiente opera como práctica colaborativa entre inteligencias heterogéneas.',
      },
      {
        id:'w19',
        title:'Unsupervised',
        author:'Refik Anadol',
        year:2022,
        sci:0.90,
        features:{ sensors:0.40, estado:0.70, adapt:0.70, autonomia:0.50, afecto:0.40 },
        text:`Unsupervised utiliza modelos de aprendizaje automático entrenados con colecciones del MoMA para producir flujos visuales autónomos en tiempo real, tomando al museo como materia estadística. Convierte el archivo institucional en interpretación algorítmica continua y proyecta una memoria maquínica que sueña el acervo, en el extremo del mapa de la estética sintiente.`,
        media:{type:'iframe', src:'https://www.youtube.com/embed/7uSLL4m6reU'},
        caption: 'Modelos entrenados con la colección del MoMA generan flujos visuales autónomos en vivo, transformando el archivo en proceso de interpretación algorítmica. La obra sugiere una memoria maquínica que “sueña” el acervo y consolida la imagen de una máquina que produce imaginarios propios mediante datos, cálculo masivo y espectáculo perceptivo.',
      }
    ];

    const CENTRAL_NODE = {
      id:'centro',
      title:'Hacia una Estética Sintiente',
      subtitle:'Omar Jaimes Rew',
      text:[
        'Este ensayo se articula a partir de la visualización de datos como herramienta metodológica para la investigación y la práctica curatorial. Su estructura formal se inspira en una ecuación de regresión lineal: un modelo tridimensional que mapea, en tres dimensiones interrelacionadas, diversas piezas artísticas con el objetivo de evidenciar su pertinencia, sus tensiones y los patrones que configuran la emergencia de una “estética sintiente”.',
        'Comencemos por delimitar el término “sintiente”. Habitamos un entorno donde las tecnologías digitales se han expandido de forma sistemática. Sistemas de inteligencia artificial perciben el mundo mediante cámaras, micrófonos, sensores de profundidad, temperatura y otros dispositivos, integrados en objetos cotidianos como el teléfono móvil. Esta infraestructura técnico-perceptiva configura entornos poblados por artefactos capaces de captar información, procesarla y reaccionar a su contexto. Sin embargo, esa capacidad de detección y respuesta no basta para afirmar que estos objetos “sienten”.',
        'Sentir supone más que gestionar entradas de datos. Exige la posibilidad de una interioridad mínima, una organización propia de la experiencia que interpreta, valora y jerarquiza lo percibido. Desde la filosofía de la mente y ciertas perspectivas fenomenológicas, la sintiencia se vincula con una experiencia situada, encarnada y autoreferencial, no reducible al cálculo ni a la mera correlación estadística. En este marco, los sistemas actuales pueden describirse como sensibles a variables, pero no como entidades sintientes.',
        'En el campo del arte, la incorporación de estas tecnologías ha dado lugar a nuevas categorías, entre ellas el arte interactivo, entendido como aquel conjunto de prácticas en las que la obra ajusta su comportamiento, configuración o apariencia en función de la acción del público o de las variaciones del entorno. El objetivo de este ensayo se ancla en discutir qué tan cerca o lejos nos encontramos de dispositivos artísticos sintientes: obras concebidas como sistemas capaces de percibir, procesar e interpretar información de su contexto y, a partir de ello, modular su forma, su respuesta y su efecto estético. Pensar una “estética sintiente” implica desplazar la obra de arte de la condición de objeto estable hacia la de agente perceptivo que negocia, en tiempo real, su modo de aparecer.'
      ],
      media:{
        type:'image',
        src:'data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" width="600" height="338"><rect width="100%" height="100%" fill="black"/><text x="50%" y="45%" dominant-baseline="middle" text-anchor="middle" fill="white" font-family="Arial" font-size="18">Hacia una Estética Sintiente</text><text x="50%" y="60%" dominant-baseline="middle" text-anchor="middle" fill="white" font-family="Arial" font-size="14">Omar Jaimes Rew</text></svg>'
      }
    };

    // ===================== ESCENA Y CONTROLES =====================
    const canvas = document.getElementById('webgl');
    const renderer = new THREE.WebGLRenderer({ canvas, antialias: true });
    renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
    renderer.setSize(window.innerWidth, window.innerHeight);
    renderer.toneMapping = THREE.ReinhardToneMapping;
    renderer.toneMappingExposure = 1.1;

    const scene = new THREE.Scene();
    scene.background = new THREE.Color(0x0b0d12);

    const camera = new THREE.PerspectiveCamera(60, window.innerWidth / window.innerHeight, 0.1, 200);
    camera.position.set(0.8, 1.4, 7.5);

    const controls = new OrbitControls(camera, renderer.domElement);
    controls.enableDamping = true;
    controls.enablePan = true;
    controls.zoomToCursor = true;
    controls.zoomSpeed = 0.5;
    controls.minDistance = 1.2;
    controls.maxDistance = 120;

    scene.add(new THREE.AmbientLight(0xffffff, 0.4));
    const dir = new THREE.DirectionalLight(0xffffff, 0.4); dir.position.set(3,5,6); scene.add(dir);

    // Postprocesado: bloom para que los nodos emanen luz
    const composer = new EffectComposer(renderer);
    const renderPass = new RenderPass(scene, camera);
    composer.addPass(renderPass);
    const bloomPass = new UnrealBloomPass(
      new THREE.Vector2(window.innerWidth, window.innerHeight),
      1.3,   // intensidad del halo
      0.4,   // radio
      0.0    // umbral, todo lo brillante contribuye
    );
    composer.addPass(bloomPass);

    // ===================== MAPEO A COORDENADAS =====================
    const years = WORKS.map(w=>w.year);
    const Ymin = Math.min(...years), Ymax = Math.max(...years);

    const X_RANGE = 12;
    const Y_RANGE = 8;
    const Z_RANGE = 8;

    const xFromYear  = y   => ((y - Ymin)/(Ymax - Ymin) - 0.5) * X_RANGE;
    const yFromScore = s   => (s - 0.5) * Y_RANGE;
    const zFromSci   = sci => (sci - 0.5) * Z_RANGE;

    const yearFromX = x => { const r = (x / X_RANGE) + 0.5; return Ymin + r * (Ymax - Ymin); };
    const scoreFromY = y => (y / Y_RANGE) + 0.5;
    const sciFromZ   = z => (z / Z_RANGE) + 0.5;

    const minX = xFromYear(Ymin), maxX = xFromYear(Ymax);
    const yLow = -Y_RANGE/2, yHigh = Y_RANGE/2;
    const zLow = -Z_RANGE/2, zHigh = Z_RANGE/2;

    const AXES_VISIBLE = false;
    const axisLines = [];

    const dataBox = new THREE.Box3(
      new THREE.Vector3(minX, yLow, zLow),
      new THREE.Vector3(maxX, yHigh, zHigh)
    );

    // ===================== SCORE IMPLEMENTADO =====================
    const clamp01 = v => Math.max(0, Math.min(1, v));
    const xNormYear = y => (y - Ymin) / (Ymax - Ymin);

    function scoreFromFeatures(f){
      const w = WEIGHTS;
      return (f.sensors||0)*w.sensors + (f.estado||0)*w.estado + (f.adapt||0)*w.adapt + (f.autonomia||0)*w.autonomia + (f.afecto||0)*w.afecto;
    }
    function implementedScore(work){
      const base = work.features ? scoreFromFeatures(work.features) : (typeof work.score === 'number' ? work.score : 0.5);
      const boosted = base + TECH_BOOST * xNormYear(work.year);
      return clamp01(boosted);
    }

    // ===================== AJUSTES DINÁMICOS (COLOR / BRILLO) =====================
    let COLOR_FLOOR = 0.05;      // mezcla hacia blanco para separar tonos
    let BRIGHT_BASE = 0.15;      // brillo mínimo
    let BRIGHT_GAIN = 1.50;      // cuánto crece el brillo con Y
    let BRIGHT_GAMMA = 1.00;     // curva de respuesta

    // azul profundo → rosa intenso a lo largo de X (tiempo)
    const WHITE = new THREE.Color(0xffffff);
    const TIME_COLOR_START = new THREE.Color(0x2563eb); // azul
    const TIME_COLOR_END   = new THREE.Color(0xec4899); // rosa

    function colorFromTime(tX){
      tX = clamp01(tX);
      const c = TIME_COLOR_START.clone().lerp(TIME_COLOR_END, tX);
      if (COLOR_FLOOR > 0){
        // eleva ligeramente hacia blanco para evitar saturación uniforme
        c.lerp(WHITE, COLOR_FLOOR);
      }
      return c;
    }

    // luminosidad controlada por Y (sintiencia implementada)
    function brightnessFromY(tY){
      const y = Math.pow(clamp01(tY), BRIGHT_GAMMA);
      const v = BRIGHT_BASE + BRIGHT_GAIN * y;
      return Math.max(0, Math.min(4.0, v)); // hasta 4 para forzar bloom en Y alta
    }

    // ===================== NODOS =====================
    const group = new THREE.Group();
    scene.add(group);

    const satGeo = new THREE.SphereGeometry(0.07, 18, 18);
    const nodes = [];

    for(const w of WORKS){
      const sPrime = implementedScore(w);
      const tX = xNormYear(w.year);
      const tY = sPrime;
      const tZ = w.sci ?? 0.5;

      const baseColor = colorFromTime(tX);
      const emissiveI = brightnessFromY(tY);

      const mat = new THREE.MeshStandardMaterial({
        color: baseColor,
        roughness: 0.55,
        metalness: 0.05,
        emissive: baseColor.clone(),
        emissiveIntensity: emissiveI
      });

      const mesh = new THREE.Mesh(satGeo, mat);
      mesh.position.set(
        xFromYear(w.year),
        yFromScore(sPrime),
        (w.sci != null ? (w.sci - 0.5) * Z_RANGE : 0)
      );
      mesh.userData = { id:w.id, label:`${w.title} (${w.year})`, sPrime, sci:w.sci, year:w.year, tX, tY, tZ };
      nodes.push(mesh);
      group.add(mesh);
    }

    const centerGeom = new THREE.SphereGeometry(0.16, 32, 32);
    const FUTURE_YEAR = 2025;
    const futureX = xFromYear(FUTURE_YEAR);
    const centerHue = colorFromTime(1);
    const centerMat  = new THREE.MeshStandardMaterial({
      color: centerHue,
      emissive: centerHue.clone(),
      emissiveIntensity: brightnessFromY(1.0), // centro muy luminoso
      roughness: 0.3,
      metalness: 0.3
    });
    const center = new THREE.Mesh(centerGeom, centerMat);
    center.position.set(futureX, yHigh, 0);
    center.userData = { id:'centro', label:'Hacia una Estética Sintiente · Omar Jaimes Rew (2025 / máx Y)', sPrime:1, sci:1, year:FUTURE_YEAR, tX:1, tY:1, tZ:1 };
    group.add(center);

    const linkLines = [];
    const lineMat = new THREE.LineBasicMaterial({ color: 0x243041, transparent:true, opacity:0.35 });
    for(const n of nodes){
      const lg = new THREE.BufferGeometry();
      lg.setAttribute('position', new THREE.BufferAttribute(new Float32Array([
        center.position.x, center.position.y, center.position.z,
        n.position.x,      n.position.y,      n.position.z
      ]),3));
      const ln = new THREE.Line(lg, lineMat);
      linkLines.push(ln);
      group.add(ln);
    }

    // ===================== OVERLAY =====================
    const overlay = document.getElementById('overlay');
    const ovTitle = document.getElementById('ov-title');
    const ovText  = document.getElementById('ov-text');
    const ovId    = document.getElementById('ov-id');
    const ovMedia = document.getElementById('ov-media');
    const ovCaption = document.getElementById('ov-caption');
    const ovClose = document.getElementById('ov-close');
    const tooltip = document.getElementById('tooltip');
    

    const HUD = {
      mode: document.getElementById('hud-mode'),
      x: document.getElementById('hud-x'),
      y: document.getElementById('hud-y'),
      z: document.getElementById('hud-z'),
      cam: document.getElementById('hud-cam')
    };

    const raycaster = new THREE.Raycaster();
    const mouse = new THREE.Vector2();

    function toNDC(event){
      const rect = renderer.domElement.getBoundingClientRect();
      mouse.x = ((event.clientX - rect.left) / rect.width) * 2 - 1;
      mouse.y = -((event.clientY - rect.top) / rect.height) * 2 + 1;
    }
    function hitTest(){
      raycaster.setFromCamera(mouse, camera);
      const objects = [center, ...nodes];
      return raycaster.intersectObjects(objects, false);
    }

    function showTooltip(obj, event){
      tooltip.textContent = obj.userData.label || obj.userData.id;
      tooltip.style.left = `${event.clientX}px`;
      tooltip.style.top  = `${event.clientY}px`;
      tooltip.style.display = 'block';
    }
    function hideTooltip(){ tooltip.style.display = 'none'; }

function buildMediaEl(media){
  if(!media) return null;

  let el = null;

  if(media.type === 'image'){
    el = new Image();
    el.src = media.src;
    el.alt = media.alt || '';
  } else if(media.type === 'video'){
    el = document.createElement('video');
    el.src = media.src;
    el.controls = true;
    el.playsInline = true;
  } else if(media.type === 'audio'){
    el = document.createElement('audio');
    el.src = media.src;
    el.controls = true;
  } else if(media.type === 'iframe'){
    el = document.createElement('iframe');
    el.width = media.width || 560;
    el.height = media.height || 315;
    const src = media.src || '';        // sin tocar el dominio
    el.src = src;
    el.title = media.title || 'YouTube video player';
    el.frameBorder = '0';
    el.allow = 'accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share';
    el.referrerPolicy = media.referrerPolicy || 'strict-origin-when-cross-origin';
    el.allowFullscreen = true;
  }

  return el;
}




    function openOverlay(id){
      ovText.innerHTML = '';
      ovMedia.innerHTML = '';
      ovCaption.textContent = '';

      if(id === 'centro'){
        ovTitle.textContent = CENTRAL_NODE.title;

        const meta = document.createElement('div');
        meta.className = 'meta';
        meta.textContent = `Autor: ${CENTRAL_NODE.subtitle || 'Omar Jaimes Rew'}`;
        ovText.appendChild(meta);

        const paragraphs = Array.isArray(CENTRAL_NODE.text)
          ? CENTRAL_NODE.text
          : (CENTRAL_NODE.text || '').split(/\n\s*\n/);

        paragraphs.forEach(par => {
          const trimmed = par.trim();
          if(!trimmed) return;
          const p = document.createElement('p');
          p.textContent = trimmed;
          ovText.appendChild(p);
        });

        ovId.textContent = `ID: ${id}`;
      } else {
        const data = WORKS.find(w=>w.id===id);
        if(!data) return;

        ovTitle.textContent = data.title;

        const meta = document.createElement('div');
        meta.className = 'meta';
        meta.textContent = `${data.author||''} · ${data.year||''}`;
        ovText.appendChild(meta);

        const p = document.createElement('p');
        p.textContent = data.text || '';
        ovText.appendChild(p);

    

        const kv = document.createElement('p');
        kv.innerHTML = `<strong>Índice Y (implementado):</strong> ${implementedScore(data).toFixed(2)} · <strong>Z (ciencia):</strong> ${(data.sci??0).toFixed(2)}`;
        ovText.appendChild(kv);

        ovId.textContent = `ID: ${id}`;

        const el = buildMediaEl(data.media);
        if(el) ovMedia.appendChild(el);

        if(data.caption){
    ovCaption.textContent = data.caption;
  }


      }

      overlay.classList.add('show');
      overlay.setAttribute('aria-hidden','false');
    }

    function closeOverlay(){
      overlay.classList.remove('show');
      overlay.setAttribute('aria-hidden','true');
    }
    ovClose.addEventListener('click', closeOverlay);
    window.addEventListener('keydown', (e)=>{ if(e.key==='Escape') closeOverlay(); });

    // ===================== HUD =====================
    const tmpPoint = new THREE.Vector3();

    function updateHudFromPoint(pt){
      const year = Math.round(yearFromX(pt.x));
      const yIdx = clamp01(scoreFromY(pt.y));
      const zSci = clamp01(sciFromZ(pt.z));
      HUD.x.textContent = isFinite(year) ? String(year) : '—';
      HUD.y.textContent = isFinite(yIdx) ? yIdx.toFixed(2) : '—';
      HUD.z.textContent = isFinite(zSci) ? zSci.toFixed(2) : '—';
    }

    function updateHudCamera(){
      const d = camera.position.distanceTo(controls.target);
      HUD.cam.textContent = `dist:${d.toFixed(2)} fov:${camera.fov.toFixed(0)}°`;
    }

    function updateHUD(){
      updateHudCamera();
      raycaster.setFromCamera(mouse, camera);
      const hit = hitTest();
      if(hit.length){
        const o = hit[0].object;
        HUD.mode.textContent = 'nodo';
        HUD.x.textContent = (o.userData.year ?? Math.round(yearFromX(o.position.x))).toString();
        HUD.y.textContent = (o.userData.sPrime ?? clamp01(scoreFromY(o.position.y))).toFixed(2);
        HUD.z.textContent = (o.userData.sci   ?? clamp01(sciFromZ(o.position.z))).toFixed(2);
        return;
      }
      HUD.mode.textContent = 'volumen';
      if(raycaster.ray.intersectBox(dataBox, tmpPoint)) updateHudFromPoint(tmpPoint);
      else HUD.x.textContent = HUD.y.textContent = HUD.z.textContent = '—';
    }

    // ===================== CONTROLES EN VIVO =====================
    const UI = {
      floor: document.getElementById('ctl-floor'),
      bbase: document.getElementById('ctl-bbase'),
      bgain: document.getElementById('ctl-bgain'),
      bgamma: document.getElementById('ctl-bgamma'),
      vFloor: document.getElementById('val-floor'),
      vBbase: document.getElementById('val-bbase'),
      vBgain: document.getElementById('val-bgain'),
      vBgamma: document.getElementById('val-bgamma')
    };

    function applyColorAndEmission(mesh){
      const baseColor = colorFromTime(mesh.userData.tX);
      mesh.material.color.copy(baseColor);
      mesh.material.emissive.copy(baseColor);
      mesh.material.emissiveIntensity = brightnessFromY(mesh.userData.tY);
    }

    function refreshAppearance(){
      for(const n of nodes) applyColorAndEmission(n);
      applyColorAndEmission(center);
    }

    function updateUIValues(){
      UI.vFloor.textContent = COLOR_FLOOR.toFixed(2);
      UI.vBbase.textContent = BRIGHT_BASE.toFixed(2);
      UI.vBgain.textContent = BRIGHT_GAIN.toFixed(2);
      UI.vBgamma.textContent = BRIGHT_GAMMA.toFixed(2);
    }

    function bindLiveControls(){
      UI.floor.addEventListener('input', ()=>{ COLOR_FLOOR = parseFloat(UI.floor.value); updateUIValues(); refreshAppearance(); });
      UI.bbase.addEventListener('input', ()=>{ BRIGHT_BASE = parseFloat(UI.bbase.value); updateUIValues(); refreshAppearance(); });
      UI.bgain.addEventListener('input', ()=>{ BRIGHT_GAIN = parseFloat(UI.bgain.value); updateUIValues(); refreshAppearance(); });
      UI.bgamma.addEventListener('input', ()=>{ BRIGHT_GAMMA = parseFloat(UI.bgamma.value); updateUIValues(); refreshAppearance(); });
      updateUIValues();
    }

    bindLiveControls();

    // ===================== INTERACCIÓN =====================
    let pointerDown = null;
    renderer.domElement.addEventListener('pointerdown', e => { pointerDown = {x:e.clientX, y:e.clientY}; });
    renderer.domElement.addEventListener('pointermove', e => {
      toNDC(e);
      const hits = hitTest();
      if(hits.length){
        renderer.domElement.style.cursor = 'pointer';
        showTooltip(hits[0].object, e);
      } else {
        renderer.domElement.style.cursor = 'default';
        hideTooltip();
      }
      updateHUD();
    });
    renderer.domElement.addEventListener('pointerup', e => {
      if(pointerDown){
        const dx = Math.abs(e.clientX - pointerDown.x);
        const dy = Math.abs(e.clientY - pointerDown.y);
        if(dx > 4 || dy > 4){ pointerDown = null; return; }
      }
      toNDC(e);
      const hits = hitTest();
      if(hits.length) openOverlay(hits[0].object.userData.id);
      pointerDown = null;
      updateHUD();
    });

    renderer.domElement.addEventListener('wheel', e => {
      toNDC(e);
    }, { passive: true });

    function onResize(){
      const w = window.innerWidth, h = window.innerHeight;
      renderer.setSize(w, h);
      composer.setSize(w, h);
      bloomPass.setSize(w, h);
      camera.aspect = w/h;
      camera.updateProjectionMatrix();
      updateHudCamera();
    }
    window.addEventListener('resize', onResize);

    const clock = new THREE.Clock();
    const ROT_SPEED_Y = 0.04; // giro muy lento horizontal (eje Y)

    // ===================== PULSOS DE LUZ EN LOS HILOS =====================
    const packets = [];
    const packetGeo = new THREE.SphereGeometry(0.02, 8, 8);
    const tmpPacketVec = new THREE.Vector3();

    for (const n of nodes) {
      const c = new THREE.Color(0xffffff);
      const pm = new THREE.MeshStandardMaterial({
        color: c,
        emissive: c.clone(),
        emissiveIntensity: 0.6,
        transparent: true,
        opacity: 0.5,
        roughness: 0.5,
        metalness: 0.05
      });
      const p = new THREE.Mesh(packetGeo, pm);
      const packetLight = new THREE.PointLight(c, 0.0, 1.6, 2.0);
      packetLight.castShadow = false;
      p.add(packetLight);
      p.userData = {
        start: n.position.clone(),
        end: center.position.clone(),
        offset: Math.random(),
        speed: 0.10 + Math.random() *0.5,
        light: packetLight
      };
      p.position.copy(p.userData.start);
      group.add(p);
      packets.push(p);
    }

    // ===================== TESTS BÁSICOS =====================
    // Overlay inicial: nodo principal
    openOverlay('centro');

    // ===================== LOOP DE ANIMACIÓN =====================
    function animate(){
      const delta = clock.getDelta();
      const elapsed = clock.elapsedTime;

      // rotación horizontal lenta del conjunto sobre eje Y
      group.rotation.y += ROT_SPEED_Y * delta;

      // pulsos discretos hijo → centro
      for (const p of packets) {
        const u = (elapsed * p.userData.speed + p.userData.offset) % 1; // 0..1
        tmpPacketVec.copy(p.userData.start).lerp(p.userData.end, u);
        p.position.copy(tmpPacketVec);
        const pulse = Math.sin(u * Math.PI); // 0→1→0
        const emission = 0.20 + 0.45 * pulse;
        p.material.opacity = 0.02 + 0.08 * pulse;
        p.material.emissiveIntensity = emission;
        if (p.userData.light) {
          p.userData.light.intensity = 0.35 + 1.25 * pulse;
        }
      }

      controls.update();
      updateHUD();
      composer.render();
      requestAnimationFrame(animate);
    }

    animate();
  </script>
</body>
</html>